{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste das classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do código nos 3 arquivos disponibilizados no repositório."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncsv_file = 'portalbio_export_17-10-2019-13-06-22.csv'  # Arquivo CSV que será carregado\\ncsv_open = FindNan(csv_file)  # Criação da instância da classe MyData\\nmean_nan_values = csv_open.getEmpty() #  Utiliza o método para obter as células vazias\\ncsv_open.printReport()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3mas pia\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct 28 10:06:11 2019\n",
    "\n",
    "@author: alexandremarcondes\n",
    "\"\"\"\n",
    "\n",
    "# Bibliotecas\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Classes\n",
    "class FindNan:\n",
    "    \n",
    "    def __init__(self, my_csv):\n",
    "        try:\n",
    "            self.df = pd.read_csv(my_csv, sep='\\n', delimiter=';')  # Cria o verificaTaxonomiaAsNumpydataframe através do arquivo CSV\n",
    "            self.nan_df = []\n",
    "        except IOError as e:\n",
    "            print('Could not read the file', my_csv) # Caso o arquivo com o nome citado não exista, o programa é encerrado\n",
    "            print ('I/O error({0}): {1}'.format(e.errno, e.strerror))  # Indica o erro ocorrido \n",
    "            sys.exit()\n",
    "        \n",
    "        self.fields = list(self.df)  # Cria uma lista com todos os campos presentes no CSV\n",
    "        self.n_lines = len(self.df)  # Atribui o número de linhas do arquivo a variável n_lines\n",
    "     \n",
    "    def getEmpty(self):  # Método que retorna a média de dados faltantes por campo no arquivo CSV\n",
    "        count_mean = {}  # Dicionário com a média de dados faltantes pela quantidade de linhas\n",
    "        for field in self.fields:  # Itera sobre cada campo na lista de campos do arquivo CSV\n",
    "            \n",
    "            # List comprehension:\n",
    "            # Soma 1 se a célula não tiver informação ou 0 se a célula tiver informação \n",
    "            count_mean[field] = sum([1 if value == \"\" or value == \"Sem Informações\" else 0 for value in self.df[field]])\n",
    "            \n",
    "            # Divide a soma dos dados faltantes pelo número de linhas para obtger a média\n",
    "            count_mean[field] = (count_mean[field]/self.n_lines)*100  #  A multiplicação por 100 obtém a porcentagem dos dados faltantes\n",
    "        self.nan_df = pd.DataFrame([count_mean])  # Transforma o dicionário em um dataframe com as porcentagens de dados faltantes\n",
    "        return self.nan_df\n",
    "    \n",
    "    def printReport(self): # Método que envia um relatório dos dados faltantes\n",
    "        fr = open('report', 'w')\n",
    "        print('\\n')\n",
    "        print('***********************************************')\n",
    "        print('Relatório dos dados faltantes')\n",
    "        print('***********************************************')\n",
    "        print('\\n')\n",
    "        fr.write('item'+';'+'dados faltantes(%)'+'\\n')\n",
    "        for column in self.nan_df.columns:\n",
    "            print(column , ':', self.nan_df[column].values[0], ' %')  # Printa os dados faltantes na tela\n",
    "            fr.write(column+';'+str(self.nan_df[column].values[0])+'\\n') # Gera um CSV com a porcentagem dos dados faltantes\n",
    "        fr.close()\n",
    "        return fr  # O método retorna o arquivo com o relatório de dados faltantes\n",
    "                    # A primeira linha do arquivo são os títulos das colunas\n",
    "    \n",
    "        \n",
    "'''\n",
    "csv_file = 'portalbio_export_17-10-2019-13-06-22.csv'  # Arquivo CSV que será carregado\n",
    "csv_open = FindNan(csv_file)  # Criação da instância da classe MyData\n",
    "mean_nan_values = csv_open.getEmpty() #  Utiliza o método para obter as células vazias\n",
    "csv_open.printReport()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 17 14:24:37 2019\n",
    "@author: felipe\n",
    "exPyBIO: equipe\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#esta classe utiliza métodos estáticos @staticmethod\n",
    "#estes métodos podem ser acessados fora dos objetos, como se fosse uma função solta. É como se apenas estivesse agrupando as funçoes para\n",
    "#não ficaram perdidas ao importar para outros arquivos\n",
    "\n",
    "# exemplo: from Felipe import AvaliaTax\n",
    "# meusDados = leiaTudo(arquivo)\n",
    "# AnaliaTax.verificaTaxonomia(meusDados)\n",
    "# \n",
    "# Não precisa fazer:\n",
    "# meuObjeto = AvaliaTax()\n",
    "# e depois: meuObjeto.verificaTaxonomia(meusDados)\n",
    "# pois neste projeto só vai ter 1 objeto AvaliaTax, não faz sentido eu criar mais de um. \n",
    "# \n",
    "# quando uma classe vira um aglomerado de funções, para projetos pequenos, fica mais fácil de entender. \n",
    "\n",
    "class AvaliaTax:\n",
    "    \n",
    "    #shared atribute\n",
    "    defaultFile =  \"portalbio_export_16-10-2019-14-39-54.csv\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Nao precisa instanciar esta classe, pode fazer AvaliaTax.metodo() para utilizar as funções\")\n",
    "    \n",
    "    #usar este método apenas para testes internos. Utilizar o método da classe MyData para carregar o arquivo\n",
    "    @staticmethod\n",
    "    def carregarCSV(path=None):\n",
    "      \n",
    "        # caso não tenha parâmetro: pegar do arquivo padrão:\n",
    "        caminho = path if path else AvaliaTax.defaultFile\n",
    "        \n",
    "        arquivo = None\n",
    "        \n",
    "        try:\n",
    "            arquivo = open(caminho, \"r\")\n",
    "        except IOError as e:\n",
    "            print (\"erro ao abrir o arquivo: \" , e.args)\n",
    "            return\n",
    "        \n",
    "        # Lê tudo de uma vez:    \n",
    "        base = arquivo.readlines()\n",
    "        \n",
    "        arquivo.close()\n",
    "            \n",
    "        dadosXY = list()\n",
    "    \n",
    "        # Converte CSV em matriz\n",
    "        \n",
    "        try:\n",
    "            dadosXY = list(map(lambda l: l.split(\";\"), base))\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print (\"Falha ao processar o arquivo CSV, deve ter muitas colunas faltando. \" , e.args)\n",
    "        \n",
    "        return dadosXY\n",
    "    \n",
    "    @staticmethod\n",
    "    def getColuna(k,dados):\n",
    "        return map(lambda x:x[k], dados )\n",
    "    \n",
    "    \n",
    "    # verifica se tem uma celula fazia ou não:\n",
    "    @staticmethod\n",
    "    def vazio(celula): return celula == \"Sem Informações\" or celula == \"\"\n",
    "    \n",
    "    vaziop = \"Sem Informações\" # atributo shared\n",
    "    \n",
    "    #no python3 colocar o list antes do map\n",
    "    #implementação antiga:\n",
    "    @staticmethod\n",
    "    def verificaTaxonomia(dados):\n",
    "        \"\"\"\n",
    "            nível taxonomico: [1-7]\n",
    "            reino filo classe ordem familia genero especie\n",
    "            \n",
    "            exemplo: nivel = 5\n",
    "                    1        2   3             4         5\n",
    "               Animal Chordata Aves Ciconiiformes Ardeidae 0 0\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        dadosXY = dados[1::] # pega apenas o campo dos dados (Retira o rotulo)\n",
    "       \n",
    "        nivelTaxonomico = list()\n",
    "        \n",
    "        try:\n",
    "            colunaFilo = dados[0].index('Filo') #captura o índice do rotulo que contem o filo\n",
    "            \n",
    "            #alguns reinos estão faltando\n",
    "            #quando se tem o Filo, o reino é obvio, então começamos a percorrer \n",
    "            #a partir do filo\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print( \"formato dos rótulso inválido ou sem a classificação taxonomica: \", e.args)\n",
    "            return # sair da função\n",
    "        \n",
    "        for linha in dadosXY:\n",
    "        \n",
    "            tax = linha[colunaFilo:colunaFilo+7] # examina apenas as colunas com a classificação \n",
    "             # para cada coluna que contem a taxonomia ver quais são nulas, \n",
    "             # caso nenhuma coluna é nula a classificacao é completa: 7\n",
    "            nivel =  7 - sum ( list(map(AvaliaTax.vazio, tax))  )\n",
    "             \n",
    "             # adiciona o nível calculado na listagem geral\n",
    "            nivelTaxonomico.append(nivel)\n",
    "        \n",
    "        return nivelTaxonomico\n",
    "    \n",
    "    @staticmethod\n",
    "    def listaMetodos(): return dir(AvaliaTax)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pandasAdapter(pandaDataframe):\n",
    "        out = pandaDataframe.to_numpy()\n",
    "        \n",
    "        outlist =  np.array(out, dtype=str).tolist()\n",
    "        \n",
    "        outlist.insert(0, list(pandaDataframe))\n",
    "        \n",
    "        return outlist\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def verificaTaxonomiaAsNumpy(dadosd):\n",
    "        \n",
    "        '''\n",
    "        Entrada: lista das listas de todos os dados, incluindo o cabeçalho, use o Adapter para funcionar com o Pandas\n",
    "        Saída: faz o mesmo do verificaTaxonomia(dados), porém retorna uma lista 1D de números no formato do numpy\n",
    "        este método é mais resumido devido as funcionalidados do numpy.\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "            dadosnp = np.array(dadosd[1::]) #converte os dados (e exclui o cabeçalho)\n",
    "        except TypeError as e:\n",
    "            print(\"tipo inválido, muitas colunas faltantes ou numpy não importado/instalado: \", e.args)\n",
    "            print(\"use import numpy as np ou !conda install numpy=1.16.15\")\n",
    "            return -1\n",
    "        \n",
    "        #verifica em que lugar da tabela tem a taxonomia\n",
    "        try:\n",
    "            colunaFilo = dadosd[0].index('Filo')\n",
    "        except ValueError:\n",
    "            print(\"falha ao procurar as colunas do nível taxonomico, verifique se está no formato 'filo'\")\n",
    "            return -1\n",
    "        \n",
    "        \n",
    "        #aqui acontece o procedimento (ver detalhes na documentação)\n",
    "        #usei a técnica da máscara de matriz\n",
    "        return 7 - np.sum( dadosnp[:,colunaFilo:colunaFilo+6] == AvaliaTax.vaziop , 1)\n",
    "\n",
    "dados = AvaliaTax.carregarCSV()\n",
    "# print(dados)\n",
    "AvaliaTax.verificaTaxonomia(dados)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Nome da instituicao', 1: 'Sigla da instituicao', 2: 'Nome da base de dados', 3: 'Sigla da base de dados', 4: 'Responsavel pelo registro', 5: 'Numero do registro no portal', 6: 'Numero do registro na base de dados', 7: 'Data do registro', 8: 'Data do evento', 9: 'Data de Carencia', 10: 'Nome cientifico', 11: 'Nome comum', 12: 'Nome cientifico na base de dados', 13: 'Nivel taxonomico', 14: 'Numero de individuos', 15: 'Reino', 16: 'Filo', 17: 'Classe', 18: 'Ordem', 19: 'Familia', 20: 'Genero', 21: 'Especie', 22: 'Estado de conservacao', 23: 'Categoria de Ameaca', 24: 'Localidade', 25: 'Pais', 26: 'Estado/Provincia', 27: 'Municipio', 28: 'Status de Sensibilidade', 29: 'Latitude', 30: 'Longitude', 31: 'Outras informacoes da localidade', 32: 'Jurisdicao', 33: 'Destino do Material'}\n",
      " PLEASE, ENTER THE INDICES YOU WOULD LIKE TO FILTER, SEPARATED BY SPACE: \n",
      "0\n",
      "Nome da instituicao: sem informações\n",
      "\n",
      "Based on the options above, Nome da instituicao:asdas\n",
      "result for: asdas\n",
      "result is empty\n",
      "would you like to save the result [yes]/no?no\n",
      "file not saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Thu Oct 28 16:00 2019\n",
    "@author: Wana \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "'''\n",
    "The above ANSI escape code will set the text colour to bright green. The format is;\n",
    "\\033[  Escape code, this is always the same\n",
    "1 = Style, 1 for normal.\n",
    "32 = Text colour, 32 for bright green.\n",
    "40m = Background colour, 40 is for black.\n",
    "'''\n",
    "#Atividade 3\n",
    "\n",
    "class wana:\n",
    "\tdados = []\n",
    "\tdf = None\n",
    "\tdict_header = {}\n",
    "\theader = None\n",
    "\tauxh = []\n",
    "\tdef __init__(self, file, sep):\n",
    "\n",
    "\t\ttry:\n",
    "\n",
    "\t\t\tself.file = pd.read_csv(file, sep=sep)\n",
    "\n",
    "\t\texcept:\n",
    "\t\t\tprint('Could not open the file')\n",
    "\t\t\tsys.exit(1)\n",
    "\n",
    "\tdef dict(self):\n",
    "\t\tself.df = self.file.apply(lambda x: x.astype(str).str.lower()) # turn all my data to lower case\n",
    "\t\tself.header = self.df.columns.tolist() # getting the list of header' names\n",
    "\t\t#creating a dictionary with c1olumn' names\n",
    "\t\tfor i in range(len(self.header)):\n",
    "\t\t\tself.dict_header[i] = self.header[i]\n",
    "\n",
    "\tdef entry(self):\n",
    "\t\tself.dict()\n",
    "\t\tentry = input('\\033[1;31;47m{}\\n\\033[1;30;47m PLEASE, ENTER THE INDICES YOU WOULD LIKE TO FILTER, SEPARATED BY SPACE: \\n'.format(self.dict_header))\n",
    "\t\tlist_filter  = entry.split() # turning it in a list os string\n",
    "\t\tint_list = [int(i) for i in list_filter] #list comprehansion to convert the string values into int values\n",
    "\t\tfor i in int_list:\n",
    "\t\t\tfor j in range(len(self.header)):\n",
    "\t\t\t\tif i == j:\n",
    "\t\t\t\t\tself.dfaux = list(set(self.df[self.header[i]]))\n",
    "\t\t\t\t\tprint(\"{}: {}\".format(self.header[i],', '.join(self.dfaux)))\n",
    "\t\t\t\t\tprint(\"\")\n",
    "\t\t\t\t\tf = input('Based on the options above, %s:' %self.header[i])\n",
    "\t\t\t\t\tself.auxh.append(self.header[i])\n",
    "\t\t\t\t\tself.dados.append(f)\n",
    "\n",
    "\n",
    "\tdef show_and_save(self):\n",
    "\t\tself.dict()\n",
    "\t\tself.entry()\n",
    "\t\tfor k in range(len(self.dados)):\n",
    "\t\t# selecting rows based on condition \n",
    "\t\t\tdata = self.df[self.df[self.auxh[k]] == self.dados[k]] \n",
    "\n",
    "\t\tprint('result for:' , '-'.join(i for i in self.dados))\n",
    "\t\tprint(data) if len(data) > 0 else print('result is empty')\n",
    "\t\ta = input(\"would you like to save the result [yes]/no?\")\n",
    "\t\tif a == 'no':\n",
    "\t\t\tprint('file not saved')\n",
    "\t\telif a == 'yes' or a == '':\n",
    "\t\t\texemplo= \"/home/wanabb/repo-git/repositorio-git/pesquisa1.csv\"\n",
    "\t\t\toutput = input('enter with the path and name, ex: %s \\n' %exemplo)\n",
    "\t\t\tdata.to_csv(output, sep=';')\n",
    "\t\t\tprint('file saved')\n",
    "\t\telse:\n",
    "\t\t\tprint('wrong answer, try again :(')\n",
    "\t\t\t\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "\tf = 'portalbio_export_04-11-2019-20-52-40.csv'\n",
    "\ts = ';'\n",
    "\tr = wana(f,s)\n",
    "\tr.show_and_save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Teste da classe:\\nm = mapear(\"iris.csv\")\\nprint(m.dados.head())\\nn = mapear(\"portalbio_export_16-10-2019-14-39-54.csv\", \";\")\\n\\n# Posição válida\\nprint(\"estado csv: \", n.dados.at[5,\"Estado/Provincia\"])\\nprint(\"municipio csv: \", n.dados.at[5,\"Municipio\"])\\nprint(n.dados.at[5,\"Latitude\"],n.dados.at[5,\"Longitude\"])\\nprint(n.validar_localidade(n.dados.at[5,\"Latitude\"],n.dados.at[5,\"Longitude\"],n.dados.at[5,\"Estado/Provincia\"]))\\n\\n# Posição inválida\\nprint(\"estado csv: \", n.dados.at[246,\"Estado/Provincia\"])\\nprint(\"municipio csv: \", n.dados.at[246,\"Municipio\"])\\nprint(n.dados.at[246,\"Latitude\"],n.dados.at[246,\"Longitude\"])\\nprint(n.validar_localidade(n.dados.at[246,\"Latitude\"],n.dados.at[246,\"Longitude\"],n.dados.at[246,\"Estado/Provincia\"]))\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "import json\n",
    "\n",
    "class mapear:\n",
    "    def __init__(self, caminho, separador = ',', chave = 'b230d495ac944577b6fd999bdfe087fd'):\n",
    "        self.dados = pd.read_csv(caminho, separador)\n",
    "        self.chave = chave\n",
    "\n",
    "    def validar_localidade(self, lat, long, estado):\n",
    "        geocode = OpenCageGeocode(self.chave)\n",
    "        resultado = geocode.reverse_geocode(lat, long)\n",
    "\n",
    "        if 'components' in resultado[0] and 'state' in resultado[0]['components'] and 'state_code' in resultado[0]['components']:\n",
    "            if resultado[0]['components']['state'] == estado or resultado[0]['components']['state_code'] == estado :\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo 1: portalbio_export_04-11-2019-20-52-40.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***********************************************\n",
      "Relatório dos dados faltantes\n",
      "***********************************************\n",
      "\n",
      "\n",
      "Nome da instituicao : 100.0  %\n",
      "Sigla da instituicao : 0.0  %\n",
      "Nome da base de dados : 0.0  %\n",
      "Sigla da base de dados : 0.0  %\n",
      "Responsavel pelo registro : 0.0  %\n",
      "Numero do registro no portal : 0.0  %\n",
      "Numero do registro na base de dados : 0.0  %\n",
      "Data do registro : 0.0  %\n",
      "Data do evento : 0.0  %\n",
      "Data de Carencia : 0.0  %\n",
      "Nome cientifico : 0.0  %\n",
      "Nome comum : 100.0  %\n",
      "Nome cientifico na base de dados : 0.0  %\n",
      "Nivel taxonomico : 0.0  %\n",
      "Numero de individuos : 0.0  %\n",
      "Reino : 100.0  %\n",
      "Filo : 0.0  %\n",
      "Classe : 0.0  %\n",
      "Ordem : 0.0  %\n",
      "Familia : 0.0  %\n",
      "Genero : 0.0  %\n",
      "Especie : 100.0  %\n",
      "Estado de conservacao : 0.0  %\n",
      "Categoria de Ameaca : 100.0  %\n",
      "Localidade : 0.0  %\n",
      "Pais : 0.0  %\n",
      "Estado/Provincia : 0.0  %\n",
      "Municipio : 7.575757575757576  %\n",
      "Status de Sensibilidade : 0.0  %\n",
      "Latitude : 0.0  %\n",
      "Longitude : 0.0  %\n",
      "Outras informacoes da localidade : 27.27272727272727  %\n",
      "Jurisdicao : 100.0  %\n",
      "Destino do Material : 0.0  %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='report' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste da classe 1\n",
    "\n",
    "csv_file = 'portalbio_export_04-11-2019-20-52-40.csv'  # Arquivo CSV que será carregado\n",
    "csv_open = FindNan(csv_file)  # Criação da instância da classe MyData\n",
    "mean_nan_values = csv_open.getEmpty() #  Utiliza o método para obter as células vazias\n",
    "csv_open.printReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'carregarCSV',\n",
       " 'defaultFile',\n",
       " 'getColuna',\n",
       " 'listaMetodos',\n",
       " 'pandasAdapter',\n",
       " 'vazio',\n",
       " 'vaziop',\n",
       " 'verificaTaxonomia',\n",
       " 'verificaTaxonomiaAsNumpy']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste da classe 2\n",
    "\n",
    "dados = AvaliaTax.carregarCSV(csv_file)\n",
    "AvaliaTax.listaMetodos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Nome da instituicao', 1: 'Sigla da instituicao', 2: 'Nome da base de dados', 3: 'Sigla da base de dados', 4: 'Responsavel pelo registro', 5: 'Numero do registro no portal', 6: 'Numero do registro na base de dados', 7: 'Data do registro', 8: 'Data do evento', 9: 'Data de Carencia', 10: 'Nome cientifico', 11: 'Nome comum', 12: 'Nome cientifico na base de dados', 13: 'Nivel taxonomico', 14: 'Numero de individuos', 15: 'Reino', 16: 'Filo', 17: 'Classe', 18: 'Ordem', 19: 'Familia', 20: 'Genero', 21: 'Especie', 22: 'Estado de conservacao', 23: 'Categoria de Ameaca', 24: 'Localidade', 25: 'Pais', 26: 'Estado/Provincia', 27: 'Municipio', 28: 'Status de Sensibilidade', 29: 'Latitude', 30: 'Longitude', 31: 'Outras informacoes da localidade', 32: 'Jurisdicao', 33: 'Destino do Material'}\n",
      " PLEASE, ENTER THE INDICES YOU WOULD LIKE TO FILTER, SEPARATED BY SPACE: \n",
      "25\n",
      "Pais: brasil\n",
      "\n",
      "Based on the options above, Pais:Brasil\n",
      "result for: asdas-Brasil\n",
      "result is empty\n",
      "would you like to save the result [yes]/no?no\n",
      "file not saved\n"
     ]
    }
   ],
   "source": [
    "# Teste da classe 3\n",
    "s = ';'  # Separador\n",
    "r = wana(csv_file,s)  # criação da estância da classe wana\n",
    "r.show_and_save()  # execução do método\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estado csv:  PR\n",
      "municipio csv:  Palotina\n",
      "-24.313889 -53.911942\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.opencagedata.com', port=443): Max retries exceeded with url: /geocode/v1/json?q=-24.313889%2C-53.911942&key=b230d495ac944577b6fd999bdfe087fd (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fd83bb41450>: Failed to establish a new connection: [Errno 113] No route to host'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 113] No route to host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7fd83bb41450>: Failed to establish a new connection: [Errno 113] No route to host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.opencagedata.com', port=443): Max retries exceeded with url: /geocode/v1/json?q=-24.313889%2C-53.911942&key=b230d495ac944577b6fd999bdfe087fd (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fd83bb41450>: Failed to establish a new connection: [Errno 113] No route to host'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a507da5c063d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"municipio csv: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Municipio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Latitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidar_localidade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Latitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Estado/Provincia\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-4ce8b284969a>\u001b[0m in \u001b[0;36mvalidar_localidade\u001b[0;34m(self, lat, long, estado)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidar_localidade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mgeocode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenCageGeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mresultado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeocode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_geocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'components'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'state'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'components'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'state_code'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultado\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'components'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/opencage/geocoder.py\u001b[0m in \u001b[0;36mreverse_geocode\u001b[0;34m(self, lat, lng, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m \u001b[0mUnknownError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msomething\u001b[0m \u001b[0mgoes\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mOpenCage\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_query_for_reverse_geocoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/opencage/geocoder.py\u001b[0m in \u001b[0;36mgeocode\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python_practice/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.opencagedata.com', port=443): Max retries exceeded with url: /geocode/v1/json?q=-24.313889%2C-53.911942&key=b230d495ac944577b6fd999bdfe087fd (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fd83bb41450>: Failed to establish a new connection: [Errno 113] No route to host'))"
     ]
    }
   ],
   "source": [
    "# Teste da classe 4\n",
    "n = mapear(csv_file, \";\")\n",
    "# Posição válida\n",
    "print(\"estado csv: \", n.dados.at[5,\"Estado/Provincia\"])\n",
    "print(\"municipio csv: \", n.dados.at[5,\"Municipio\"])\n",
    "print(n.dados.at[5,\"Latitude\"],n.dados.at[5,\"Longitude\"])\n",
    "print(n.validar_localidade(n.dados.at[5,\"Latitude\"],n.dados.at[5,\"Longitude\"],n.dados.at[5,\"Estado/Provincia\"]))\n",
    "\n",
    "\n",
    "# Posição inválida\n",
    "print(\"estado csv: \", n.dados.at[50,\"Estado/Provincia\"])\n",
    "print(\"municipio csv: \", n.dados.at[50,\"Municipio\"])\n",
    "print(n.dados.at[50,\"Latitude\"],n.dados.at[50,\"Longitude\"])\n",
    "print(n.validar_localidade(n.dados.at[50,\"Latitude\"],n.dados.at[50,\"Longitude\"],n.dados.at[50,\"Estado/Provincia\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_practice] *",
   "language": "python",
   "name": "conda-env-python_practice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
